import asyncio
from typing import List, Tuple, Dict, Optional, Any
from ...domain.entities.document import DocumentEmbedding
from ...domain.ports.embedding_service import EmbeddingService
from ...domain.ports.cache_service import CacheService
from .embedding_cache_reader import EmbeddingCacheReader
from .semantic_similarity_calculator import SemanticSimilarityCalculator
from .lexical_similarity_calculator import LexicalSimilarityCalculator
from .score_combiner import ScoreCombiner

class RAGRetrievalService:
    """Servicio principal de recuperaci√≥n RAG que integra todos los componentes (Paso 5 de RAG)"""
    
    def __init__(
        self,
        embedding_service: EmbeddingService,
        cache_service: CacheService,
        semantic_weight: float = 0.7,
        lexical_weight: float = 0.3
    ):
        """
        Inicializa el servicio de recuperaci√≥n RAG
        
        Args:
            embedding_service: Servicio para generar embeddings
            cache_service: Servicio de cach√© para embeddings
            semantic_weight: Peso para similitud sem√°ntica
            lexical_weight: Peso para similitud lexical
        """
        self.embedding_service = embedding_service
        
        # Inicializar componentes
        self.cache_reader = EmbeddingCacheReader(cache_service)
        self.semantic_calculator = SemanticSimilarityCalculator(embedding_service)
        self.lexical_calculator = LexicalSimilarityCalculator()
        self.score_combiner = ScoreCombiner(semantic_weight, lexical_weight)
        
        # Estado del servicio
        self._is_initialized = False
        self._documents_cache: List[DocumentEmbedding] = []
        
        print(f"üöÄ RAGRetrievalService inicializado con pesos: sem√°ntico={semantic_weight}, lexical={lexical_weight}")
    
    async def initialize(self) -> bool:
        """
        Inicializa el servicio cargando los embeddings
        
        Returns:
            True si la inicializaci√≥n fue exitosa
        """
        try:
            print("üîÑ Inicializando RAGRetrievalService...")
            
            # Cargar embeddings desde el cach√©
            embeddings_data = await self.cache_reader.load_embeddings_from_cache()
            
            if not embeddings_data:
                print("‚ùå No se pudieron cargar los embeddings")
                return False
            
            # Guardar documentos del cach√©
            self._documents_cache = embeddings_data
            
            # Obtener estad√≠sticas
            stats = await self.cache_reader.get_cache_stats()
            print(f"üìä Embeddings cargados: {stats['total_embeddings']} documentos")
            print(f"üìä Tama√±o promedio de embedding: {stats['avg_embedding_size']:.0f} dimensiones")
            
            self._is_initialized = True
            print("‚úÖ RAGRetrievalService inicializado exitosamente")
            return True
            
        except Exception as e:
            print(f"‚ùå Error al inicializar RAGRetrievalService: {str(e)}")
            return False
    
    async def search_documents(
        self,
        query: str,
        top_k: int = 5,
        use_hybrid: bool = True
    ) -> List[Tuple[DocumentEmbedding, float, Dict[str, Any]]]:
        """
        Busca documentos relevantes usando RAG h√≠brido
        
        Args:
            query: Consulta de b√∫squeda
            top_k: N√∫mero de documentos m√°s relevantes
            use_hybrid: Si usar b√∫squeda h√≠brida (sem√°ntica + lexical)
            
        Returns:
            Lista de documentos con scores y detalles
        """
        if not self._is_initialized:
            raise RuntimeError("El servicio no ha sido inicializado. Llama a initialize() primero.")
        
        if not self._documents_cache:
            print("‚ö†Ô∏è No hay documentos en el cach√©")
            return []
        
        print(f"üîç Buscando documentos para: '{query}' (top_k={top_k}, hybrid={use_hybrid})")
        
        try:
            if use_hybrid:
                return await self._hybrid_search(query, top_k)
            else:
                return await self._semantic_only_search(query, top_k)
                
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda: {str(e)}")
            return []
    
    async def _hybrid_search(
        self,
        query: str,
        top_k: int
    ) -> List[Tuple[DocumentEmbedding, float, Dict[str, Any]]]:
        """
        Realiza b√∫squeda h√≠brida (sem√°ntica + lexical)
        """
        print("üîÑ Ejecutando b√∫squeda h√≠brida...")
        
        # Ejecutar b√∫squedas en paralelo para mejor rendimiento
        semantic_task = self.semantic_calculator.calculate_query_similarity(
            query, self._documents_cache
        )
        
        lexical_task = self.lexical_calculator.calculate_query_similarity(
            query, self._documents_cache
        )
        
        # Esperar ambos resultados
        semantic_results, lexical_results = await asyncio.gather(
            semantic_task, lexical_task
        )
        
        print(f"üìä Resultados sem√°nticos: {len(semantic_results)}, lexicales: {len(lexical_results)}")
        
        # Combinar scores
        combined_results = await self.score_combiner.get_top_documents(
            semantic_results, lexical_results, top_k
        )
        
        return combined_results
    
    async def _semantic_only_search(
        self,
        query: str,
        top_k: int
    ) -> List[Tuple[DocumentEmbedding, float, Dict[str, Any]]]:
        """
        Realiza b√∫squeda solo sem√°ntica
        """
        print("üîÑ Ejecutando b√∫squeda sem√°ntica √∫nicamente...")
        
        all_semantic_results = await self.semantic_calculator.calculate_query_similarity(
            query, self._documents_cache
        )
        
        # Ordenar y tomar top_k
        all_semantic_results.sort(key=lambda x: x[1], reverse=True)
        semantic_results = all_semantic_results[:top_k]
        
        # Convertir a formato compatible con resultados h√≠bridos
        formatted_results = []
        for doc, score in semantic_results:
            score_details = {
                "semantic_score": score,
                "lexical_score": 0.0,
                "combined_score": score,
                "semantic_weight": 1.0,
                "lexical_weight": 0.0
            }
            formatted_results.append((doc, score, score_details))
        
        return formatted_results
    
    async def analyze_query_performance(
        self,
        query: str,
        top_k: int = 5
    ) -> Dict[str, Any]:
        """
        Analiza el rendimiento de una consulta comparando m√©todos
        
        Args:
            query: Consulta a analizar
            top_k: N√∫mero de documentos a recuperar
            
        Returns:
            An√°lisis detallado del rendimiento
        """
        if not self._is_initialized:
            raise RuntimeError("El servicio no ha sido inicializado")
        
        print(f"üìä Analizando rendimiento para: '{query}'")
        
        import time
        
        # Medir tiempo de b√∫squeda sem√°ntica
        start_time = time.time()
        semantic_results = await self._semantic_only_search(query, top_k)
        semantic_time = time.time() - start_time
        
        # Medir tiempo de b√∫squeda h√≠brida
        start_time = time.time()
        hybrid_results = await self._hybrid_search(query, top_k)
        hybrid_time = time.time() - start_time
        
        # Analizar distribuci√≥n de scores h√≠bridos
        score_analysis = await self.score_combiner.analyze_score_distribution(hybrid_results)
        
        analysis = {
            "query": query,
            "top_k": top_k,
            "total_documents": len(self._documents_cache),
            "performance": {
                "semantic_only_time": semantic_time,
                "hybrid_time": hybrid_time,
                "time_difference": hybrid_time - semantic_time
            },
            "results_comparison": {
                "semantic_results_count": len(semantic_results),
                "hybrid_results_count": len(hybrid_results)
            },
            "score_distribution": score_analysis,
            "top_results": {
                "semantic": [
                    {
                        "document_id": doc.document_id,
                        "score": score,
                        "content_preview": doc.content[:100] + "..." if len(doc.content) > 100 else doc.content
                    }
                    for doc, score, _ in semantic_results[:3]
                ],
                "hybrid": [
                    {
                        "document_id": doc.document_id,
                        "combined_score": score,
                        "semantic_score": details["semantic_score"],
                        "lexical_score": details["lexical_score"],
                        "content_preview": doc.content[:100] + "..." if len(doc.content) > 100 else doc.content
                    }
                    for doc, score, details in hybrid_results[:3]
                ]
            }
        }
        
        return analysis
    
    async def get_service_status(self) -> Dict[str, Any]:
        """
        Obtiene el estado actual del servicio
        
        Returns:
            Diccionario con informaci√≥n del estado
        """
        cache_stats = await self.cache_reader.get_cache_stats() if self._is_initialized else {}
        combiner_config = self.score_combiner.get_configuration()
        
        status = {
            "initialized": self._is_initialized,
            "documents_loaded": len(self._documents_cache),
            "cache_stats": cache_stats,
            "score_weights": combiner_config,
            "components": {
                "cache_reader": "‚úÖ Activo" if self._is_initialized else "‚ùå No inicializado",
                "semantic_calculator": "‚úÖ Activo",
                "lexical_calculator": "‚úÖ Activo",
                "score_combiner": "‚úÖ Activo"
            }
        }
        
        return status
    
    def update_search_weights(self, semantic_weight: float, lexical_weight: float):
        """
        Actualiza los pesos de b√∫squeda
        
        Args:
            semantic_weight: Nuevo peso sem√°ntico
            lexical_weight: Nuevo peso lexical
        """
        self.score_combiner.update_weights(semantic_weight, lexical_weight)
        print(f"üîÑ Pesos de b√∫squeda actualizados: sem√°ntico={semantic_weight}, lexical={lexical_weight}")
    
    async def refresh_cache(self) -> bool:
        """
        Refresca el cach√© de embeddings
        
        Returns:
            True si el refresh fue exitoso
        """
        print("üîÑ Refrescando cach√© de embeddings...")
        
        try:
            # Limpiar cach√© actual
            self.cache_reader.clear_cache()
            self._documents_cache.clear()
            self._is_initialized = False
            
            # Reinicializar
            return await self.initialize()
            
        except Exception as e:
            print(f"‚ùå Error al refrescar cach√©: {str(e)}")
            return False