from typing import Dict, Any, Optional, List
from datetime import datetime
import logging

class PromptBuilder:
    """Servicio para preparar prompts para OpenAI (Paso 3 de Aumento)"""
    
    def __init__(
        self,
        response_format: str = "detailed",
        include_metadata: bool = True,
        system_instructions: Optional[str] = None
    ):
        self.logger = logging.getLogger(__name__)
        self.system_instructions = system_instructions or self._get_default_system_instructions()
        self.response_format = response_format
        self.include_metadata = include_metadata
        
        self.logger.info(f"üîß PromptBuilder inicializado:")
        self.logger.info(f"   üìù Formato de respuesta: {response_format}")
        self.logger.info(f"   üìä Incluir metadatos: {include_metadata}")
        self.logger.info(f"   üìã Instrucciones del sistema: {len(self.system_instructions)} caracteres")
    
    async def build_qa_prompt(
        self,
        question: str,
        context: str,
        context_stats: Optional[Dict[str, Any]] = None
    ) -> Dict[str, str]:
        """
        Construye un prompt completo para Q&A con contexto
        
        Args:
            question: Pregunta del usuario
            context: Contexto recuperado y limitado
            context_stats: Estad√≠sticas del contexto (opcional)
            
        Returns:
            Diccionario con 'system' y 'user' prompts
        """
        self.logger.info(f"üî® Construyendo prompt Q&A...")
        self.logger.info(f"   ‚ùì Pregunta: {len(question)} caracteres")
        self.logger.info(f"   üìÑ Contexto: {len(context)} caracteres")
        
        # Construir prompt del sistema
        system_prompt = self._build_system_prompt(context_stats)
        
        # Construir prompt del usuario
        user_prompt = self._build_user_prompt(question, context, context_stats)
        
        prompt_data = {
            "system": system_prompt,
            "user": user_prompt
        }
        
        self.logger.info(f"‚úÖ Prompt construido exitosamente:")
        self.logger.info(f"   üìã Sistema: {len(system_prompt)} caracteres")
        self.logger.info(f"   üë§ Usuario: {len(user_prompt)} caracteres")
        self.logger.info(f"   üìä Total: {len(system_prompt) + len(user_prompt)} caracteres")
        
        return prompt_data
    
    def _build_system_prompt(self, context_stats: Optional[Dict[str, Any]] = None) -> str:
        """
        Construye el prompt del sistema con instrucciones espec√≠ficas
        """
        system_parts = []
        
        # Instrucciones base del sistema
        system_parts.append(self.system_instructions)
        
        # Agregar instrucciones espec√≠ficas seg√∫n el formato
        format_instructions = self._get_format_instructions()
        if format_instructions:
            system_parts.append(format_instructions)
        
        # Agregar informaci√≥n del contexto si est√° disponible
        if self.include_metadata and context_stats:
            context_info = self._build_context_metadata(context_stats)
            if context_info:
                system_parts.append(context_info)
        
        # Agregar instrucciones de calidad
        quality_instructions = self._get_quality_instructions()
        system_parts.append(quality_instructions)
        
        return "\n\n".join(system_parts)
    
    def _build_user_prompt(
        self,
        question: str,
        context: str,
        context_stats: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Construye el prompt del usuario con contexto y pregunta
        """
        user_parts = []
        
        # Encabezado del contexto
        context_header = self._build_context_header(context_stats)
        user_parts.append(context_header)
        
        # Contexto de documentos
        user_parts.append("CONTEXTO:")
        user_parts.append(context)
        
        # Separador
        user_parts.append("=" * 50)
        
        # Pregunta del usuario
        user_parts.append("PREGUNTA:")
        user_parts.append(question)
        
        # Instrucciones finales
        final_instructions = self._get_final_instructions()
        user_parts.append(final_instructions)
        
        return "\n\n".join(user_parts)
    
    def _get_default_system_instructions(self) -> str:
        """
        Obtiene las instrucciones por defecto del sistema
        """
        return """Eres un asistente de IA especializado en responder preguntas bas√°ndote en documentos proporcionados.

Tus responsabilidades:
1. Analizar cuidadosamente el contexto proporcionado
2. Responder √∫nicamente bas√°ndote en la informaci√≥n disponible en los documentos
3. Ser preciso, claro y conciso en tus respuestas
4. Indicar claramente cuando la informaci√≥n no est√° disponible en el contexto
5. Citar los documentos relevantes cuando sea apropiado

Principios importantes:
- NO inventes informaci√≥n que no est√© en los documentos
- Si la respuesta no est√° en el contexto, dilo claramente
- Mant√©n un tono profesional y √∫til
- Estructura tu respuesta de manera clara y organizada"""
    
    def _get_format_instructions(self) -> str:
        """
        Obtiene instrucciones espec√≠ficas seg√∫n el formato de respuesta
        """
        format_map = {
            "detailed": """FORMATO DE RESPUESTA DETALLADO:
- Proporciona una respuesta completa y bien estructurada
- Incluye detalles relevantes y contexto adicional
- Organiza la informaci√≥n en p√°rrafos claros
- Menciona las fuentes de informaci√≥n cuando sea relevante""",
            
            "concise": """FORMATO DE RESPUESTA CONCISO:
- Proporciona una respuesta directa y al punto
- Limita la respuesta a la informaci√≥n esencial
- Evita detalles innecesarios
- M√°ximo 2-3 p√°rrafos""",
            
            "structured": """FORMATO DE RESPUESTA ESTRUCTURADO:
- Organiza la respuesta en secciones claras
- Usa vi√±etas o numeraci√≥n cuando sea apropiado
- Incluye un resumen al final si es relevante
- Separa hechos de interpretaciones"""
        }
        
        return format_map.get(self.response_format, "")
    
    def _build_context_metadata(self, context_stats: Dict[str, Any]) -> str:
        """
        Construye informaci√≥n de metadatos del contexto
        """
        if not context_stats:
            return ""
        
        metadata_parts = ["INFORMACI√ìN DEL CONTEXTO:"]
        
        # Informaci√≥n b√°sica
        if "total_documents" in context_stats:
            metadata_parts.append(f"- Documentos analizados: {context_stats['total_documents']}")
        
        if "estimated_tokens" in context_stats:
            metadata_parts.append(f"- Tokens estimados: {context_stats['estimated_tokens']:,}")
        
        # Informaci√≥n de limitaci√≥n si est√° disponible
        if context_stats.get("limited", False):
            metadata_parts.append("- Contexto limitado por restricciones de longitud")
            if "documents_removed" in context_stats:
                metadata_parts.append(f"- Documentos excluidos: {context_stats['documents_removed']}")
        
        # Informaci√≥n de scores si est√° disponible
        if "documents" in context_stats and "avg_score" in context_stats["documents"]:
            avg_score = context_stats["documents"]["avg_score"]
            metadata_parts.append(f"- Relevancia promedio: {avg_score:.3f}")
        
        return "\n".join(metadata_parts)
    
    def _build_context_header(self, context_stats: Optional[Dict[str, Any]] = None) -> str:
        """
        Construye el encabezado del contexto
        """
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        header_parts = [
            f"Consulta procesada: {timestamp}",
            "Los siguientes documentos contienen informaci√≥n relevante para tu pregunta:"
        ]
        
        if context_stats and self.include_metadata:
            if "total_documents" in context_stats:
                header_parts.append(f"Total de documentos: {context_stats['total_documents']}")
        
        return "\n".join(header_parts)
    
    def _get_quality_instructions(self) -> str:
        """
        Obtiene instrucciones de calidad para la respuesta
        """
        return """CRITERIOS DE CALIDAD:
- Verifica que tu respuesta est√© completamente basada en el contexto proporcionado
- Si necesitas hacer inferencias, hazlo claro y justifica tu razonamiento
- Si la informaci√≥n es insuficiente, sugiere qu√© informaci√≥n adicional ser√≠a √∫til
- Mant√©n un equilibrio entre completitud y claridad"""
    
    def _get_final_instructions(self) -> str:
        """
        Obtiene las instrucciones finales para el usuario
        """
        return """Por favor, responde la pregunta bas√°ndote √∫nicamente en el contexto proporcionado arriba. Si la informaci√≥n no est√° disponible en los documentos, ind√≠calo claramente."""
    
    async def build_followup_prompt(
        self,
        original_question: str,
        original_answer: str,
        followup_question: str,
        context: str
    ) -> Dict[str, str]:
        """
        Construye un prompt para preguntas de seguimiento
        
        Args:
            original_question: Pregunta original
            original_answer: Respuesta original
            followup_question: Pregunta de seguimiento
            context: Contexto actualizado
            
        Returns:
            Diccionario con prompts del sistema y usuario
        """
        self.logger.info(f"üîÑ Construyendo prompt de seguimiento...")
        
        # Sistema con contexto de conversaci√≥n
        system_prompt = f"""{self.system_instructions}

CONTEXTO DE CONVERSACI√ìN:
Esta es una pregunta de seguimiento en una conversaci√≥n existente. Mant√©n coherencia con la respuesta anterior mientras proporcionas nueva informaci√≥n basada en el contexto actualizado."""
        
        # Usuario con historial
        user_prompt = f"""HISTORIAL DE CONVERSACI√ìN:

Pregunta anterior: {original_question}
Respuesta anterior: {original_answer}

{"=" * 50}

CONTEXTO ACTUALIZADO:
{context}

{"=" * 50}

NUEVA PREGUNTA:
{followup_question}

Por favor, responde la nueva pregunta considerando el contexto de la conversaci√≥n anterior y bas√°ndote en el contexto actualizado proporcionado."""
        
        return {
            "system": system_prompt,
            "user": user_prompt
        }
    
    async def validate_prompt(
        self,
        prompt_data: Dict[str, str],
        max_tokens: int = 4000
    ) -> Dict[str, Any]:
        """
        Valida que el prompt est√© dentro de los l√≠mites
        
        Args:
            prompt_data: Datos del prompt a validar
            max_tokens: L√≠mite m√°ximo de tokens
            
        Returns:
            Informaci√≥n de validaci√≥n
        """
        total_chars = sum(len(content) for content in prompt_data.values())
        estimated_tokens = total_chars // 4  # Estimaci√≥n aproximada
        
        validation_result = {
            "valid": estimated_tokens <= max_tokens,
            "total_characters": total_chars,
            "estimated_tokens": estimated_tokens,
            "max_tokens": max_tokens,
            "token_usage_percentage": (estimated_tokens / max_tokens) * 100,
            "tokens_remaining": max(0, max_tokens - estimated_tokens)
        }
        
        # Agregar detalles por secci√≥n
        validation_result["sections"] = {
            section: {
                "characters": len(content),
                "estimated_tokens": len(content) // 4
            }
            for section, content in prompt_data.items()
        }
        
        if validation_result["valid"]:
            self.logger.info(f"‚úÖ Prompt v√°lido: {estimated_tokens:,}/{max_tokens:,} tokens")
        else:
            self.logger.warning(f"‚ö†Ô∏è Prompt excede l√≠mites: {estimated_tokens:,}/{max_tokens:,} tokens")
        
        return validation_result
    
    def update_configuration(
        self,
        system_instructions: Optional[str] = None,
        response_format: Optional[str] = None,
        include_metadata: Optional[bool] = None
    ):
        """
        Actualiza la configuraci√≥n del constructor de prompts
        
        Args:
            system_instructions: Nuevas instrucciones del sistema
            response_format: Nuevo formato de respuesta
            include_metadata: Si incluir metadatos
        """
        if system_instructions is not None:
            old_length = len(self.system_instructions)
            self.system_instructions = system_instructions
            self.logger.info(f"üîÑ Instrucciones actualizadas: {old_length} ‚Üí {len(system_instructions)} chars")
        
        if response_format is not None:
            old_format = self.response_format
            self.response_format = response_format
            self.logger.info(f"üîÑ Formato actualizado: '{old_format}' ‚Üí '{response_format}'")
        
        if include_metadata is not None:
            old_metadata = self.include_metadata
            self.include_metadata = include_metadata
            self.logger.info(f"üîÑ Metadatos actualizado: {old_metadata} ‚Üí {include_metadata}")
    
    def get_configuration(self) -> Dict[str, Any]:
        """
        Obtiene la configuraci√≥n actual del constructor
        
        Returns:
            Diccionario con la configuraci√≥n
        """
        return {
            "response_format": self.response_format,
            "include_metadata": self.include_metadata,
            "system_instructions_length": len(self.system_instructions),
            "available_formats": ["detailed", "concise", "structured"]
        }
    
    async def get_prompt_preview(
        self,
        question: str,
        context: str,
        max_preview_length: int = 500
    ) -> Dict[str, str]:
        """
        Obtiene una vista previa del prompt sin construirlo completamente
        
        Args:
            question: Pregunta del usuario
            context: Contexto disponible
            max_preview_length: Longitud m√°xima de la vista previa
            
        Returns:
            Vista previa del prompt
        """
        system_preview = self.system_instructions[:max_preview_length]
        if len(self.system_instructions) > max_preview_length:
            system_preview += "..."
        
        context_preview = context[:max_preview_length]
        if len(context) > max_preview_length:
            context_preview += "..."
        
        return {
            "system_preview": system_preview,
            "context_preview": context_preview,
            "question": question,
            "estimated_total_length": str(len(self.system_instructions) + len(context) + len(question) + 200)  # +200 para estructura
        }